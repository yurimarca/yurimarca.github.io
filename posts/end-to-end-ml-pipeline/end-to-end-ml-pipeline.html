<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Yuri Marca">
<meta name="dcterms.date" content="2025-02-09">
<meta name="description" content="Project development is part of the MLOps course from Udacity">

<title>Building an End-to-End ML Pipeline – Yuri’s Personal Website</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-c37a40b267d3139d93432c283e34c257.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<meta property="og:title" content="Building an End-to-End ML Pipeline – Yuri’s Personal Website">
<meta property="og:description" content="Project development is part of the MLOps course from Udacity">
<meta property="og:site_name" content="Yuri's Personal Website">
<meta name="twitter:title" content="Building an End-to-End ML Pipeline – Yuri’s Personal Website">
<meta name="twitter:description" content="Project development is part of the MLOps course from Udacity">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Yuri’s Personal Website</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/yurimarca"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/yurimarca/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#building-an-end-to-end-machine-learning-pipeline-for-short-term-rental-price-prediction" id="toc-building-an-end-to-end-machine-learning-pipeline-for-short-term-rental-price-prediction" class="nav-link active" data-scroll-target="#building-an-end-to-end-machine-learning-pipeline-for-short-term-rental-price-prediction">Building an End-to-End Machine Learning Pipeline for Short-Term Rental Price Prediction</a>
  <ul class="collapse">
  <li><a href="#project-overview" id="toc-project-overview" class="nav-link" data-scroll-target="#project-overview">Project Overview</a></li>
  <li><a href="#repository-structure" id="toc-repository-structure" class="nav-link" data-scroll-target="#repository-structure">Repository Structure</a></li>
  <li><a href="#pipeline-components" id="toc-pipeline-components" class="nav-link" data-scroll-target="#pipeline-components">Pipeline Components</a>
  <ul class="collapse">
  <li><a href="#data-ingestion-get_data" id="toc-data-ingestion-get_data" class="nav-link" data-scroll-target="#data-ingestion-get_data">1. Data Ingestion (<code>get_data</code>)</a></li>
  <li><a href="#data-cleaning-basic_cleaning" id="toc-data-cleaning-basic_cleaning" class="nav-link" data-scroll-target="#data-cleaning-basic_cleaning">2. Data Cleaning (<code>basic_cleaning</code>)</a></li>
  <li><a href="#exploratory-data-analysis-eda" id="toc-exploratory-data-analysis-eda" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda">3. Exploratory Data Analysis (<code>eda</code>)</a></li>
  <li><a href="#data-validation-data_check" id="toc-data-validation-data_check" class="nav-link" data-scroll-target="#data-validation-data_check">4. Data Validation (<code>data_check</code>)</a></li>
  <li><a href="#data-splitting-train_val_test_split" id="toc-data-splitting-train_val_test_split" class="nav-link" data-scroll-target="#data-splitting-train_val_test_split">5. Data Splitting (<code>train_val_test_split</code>)</a></li>
  <li><a href="#model-training-train_random_forest" id="toc-model-training-train_random_forest" class="nav-link" data-scroll-target="#model-training-train_random_forest">6. Model Training (<code>train_random_forest</code>)</a></li>
  <li><a href="#model-evaluation-test_regression_model" id="toc-model-evaluation-test_regression_model" class="nav-link" data-scroll-target="#model-evaluation-test_regression_model">8. Model Evaluation (<code>test_regression_model</code>)</a></li>
  </ul></li>
  <li><a href="#setting-up-the-environment" id="toc-setting-up-the-environment" class="nav-link" data-scroll-target="#setting-up-the-environment">Setting Up the Environment</a></li>
  <li><a href="#pipeline-steps" id="toc-pipeline-steps" class="nav-link" data-scroll-target="#pipeline-steps">Pipeline Steps</a>
  <ul class="collapse">
  <li><a href="#step-1-downloading-the-data" id="toc-step-1-downloading-the-data" class="nav-link" data-scroll-target="#step-1-downloading-the-data">Step 1: Downloading the Data</a></li>
  <li><a href="#step-2-exploratory-data-analysis" id="toc-step-2-exploratory-data-analysis" class="nav-link" data-scroll-target="#step-2-exploratory-data-analysis">Step 2: Exploratory Data Analysis</a></li>
  <li><a href="#step-3-basic-data-cleaning" id="toc-step-3-basic-data-cleaning" class="nav-link" data-scroll-target="#step-3-basic-data-cleaning">Step 3: Basic Data Cleaning</a></li>
  <li><a href="#step-4-data-tests-validation" id="toc-step-4-data-tests-validation" class="nav-link" data-scroll-target="#step-4-data-tests-validation">Step 4: Data Tests &amp; Validation</a></li>
  <li><a href="#step-5-train-validation-test-split" id="toc-step-5-train-validation-test-split" class="nav-link" data-scroll-target="#step-5-train-validation-test-split">Step 5: Train-Validation-Test Split</a></li>
  <li><a href="#step-6-model-training-with-random-forest" id="toc-step-6-model-training-with-random-forest" class="nav-link" data-scroll-target="#step-6-model-training-with-random-forest">Step 6: Model Training with Random Forest</a></li>
  <li><a href="#step-7-model-testing-promotion" id="toc-step-7-model-testing-promotion" class="nav-link" data-scroll-target="#step-7-model-testing-promotion">Step 7: Model Testing &amp; Promotion</a></li>
  </ul></li>
  <li><a href="#putting-it-all-together-main.py" id="toc-putting-it-all-together-main.py" class="nav-link" data-scroll-target="#putting-it-all-together-main.py">Putting It All Together: <code>main.py</code></a></li>
  <li><a href="#using-cookiecutter-for-quick-pipeline-steps" id="toc-using-cookiecutter-for-quick-pipeline-steps" class="nav-link" data-scroll-target="#using-cookiecutter-for-quick-pipeline-steps">Using Cookiecutter for Quick Pipeline Steps</a></li>
  <li><a href="#deployment-and-workflow" id="toc-deployment-and-workflow" class="nav-link" data-scroll-target="#deployment-and-workflow">Deployment and Workflow</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Building an End-to-End ML Pipeline</h1>
  <div class="quarto-categories">
    <div class="quarto-category">ml pipelines</div>
    <div class="quarto-category">reproducible experiments</div>
    <div class="quarto-category">mlflow</div>
    <div class="quarto-category">wandb</div>
    <div class="quarto-category">hydra</div>
    <div class="quarto-category">python</div>
  </div>
  </div>

<div>
  <div class="description">
    Project development is part of the MLOps course from Udacity
  </div>
</div>


<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Yuri Marca </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">February 9, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="building-an-end-to-end-machine-learning-pipeline-for-short-term-rental-price-prediction" class="level1">
<h1>Building an End-to-End Machine Learning Pipeline for Short-Term Rental Price Prediction</h1>
<p>In the dynamic world of short-term property rentals, accurately predicting rental prices is crucial for maximizing occupancy and revenue. To address this challenge, I developed a comprehensive, reproducible Machine Learning (ML) pipeline tailored for short-term rental price prediction in New York City (NYC) based on Airbnb data. We walk through data collection, cleaning, validation, splitting, training a random forest model, testing the model, and logging every artifact and result in a reproducible manner. This blog post focus on the usage of <strong>MLflow</strong>, <strong>Weights &amp; Biases (W&amp;B)</strong>, and <strong>Hydra</strong> for orchestration, tracking, and hyperparameter optimization, as these are taught in the Udacity MLOps Nanodegree program.</p>
<section id="project-overview" class="level2">
<h2 class="anchored" data-anchor-id="project-overview">Project Overview</h2>
<p>Short-term rental platforms like Airbnb collect vast amounts of data from hosts and guests. A host often asks: <em>What price should I set for my listing to optimize occupancy and revenue?</em> This project aims to solve that by building an end-to-end ML pipeline to predict a short-term rental’s price given various features such as location, room type, and number of reviews.</p>
<ul>
<li><strong>Focus</strong>: Clean, reproducible, and easily re-runnable pipeline.</li>
<li><strong>Tools</strong>: MLflow for orchestration, Hydra for configuration, Weights &amp; Biases to log artifacts and metrics, and scikit-learn for model training.</li>
<li><strong>Additional</strong>: ydata-profiling for EDA, custom data checks to prevent “data drift,” and a templated approach to add new steps using a cookiecutter MLflow step.</li>
</ul>
<p>The entire pipeline is tracked under a W&amp;B project to enable experiment tracking and artifact storage. <a href="https://wandb.ai/yurimarca-ai/nyc_airbnb/">Here</a> is the link for the completed project in W&amp;B.</p>
</section>
<section id="repository-structure" class="level2">
<h2 class="anchored" data-anchor-id="repository-structure">Repository Structure</h2>
<p>The project is organized as follows:</p>
<pre><code>.
├── components/                  # Reusable pipeline components
│   ├── get_data/                # Data ingestion module
│   ├── test_regression_model/   # Model testing module
│   └── train_val_test_split/    # Data splitting module
├── src/                         # Source code for main pipeline steps
│   ├── basic_cleaning/          # Data cleaning scripts
│   ├── data_check/              # Data validation scripts
│   ├── eda/                     # Exploratory Data Analysis scripts
│   └── train_random_forest/     # Model training scripts
├── images/                      # Visual assets for documentation
├── .github/workflows/           # GitHub Actions for CI/CD
├── cookie-mlflow-step/          # Template for creating new pipeline steps
├── conda.yml                    # Conda environment configuration
├── config.yaml                  # Pipeline configuration settings
├── environment.yml              # Alternative environment configuration
├── main.py                      # Main script to run the pipeline
├── MLproject                    # MLflow project specification
└── README.md                    # Project documentation</code></pre>
<p>Key folders:</p>
<ul>
<li><strong><code>components/</code></strong>: Reusable MLflow components for tasks like data downloading, data splitting, and model testing.<br>
</li>
<li><strong><code>src/</code></strong>: Specific pipeline steps, including EDA (<code>eda</code>), data cleaning (<code>basic_cleaning</code>), data checks (<code>data_check</code>), and training a random forest (<code>train_random_forest</code>).<br>
</li>
<li><strong><code>cookie-mlflow-step/</code></strong>: A cookiecutter template that quickly scaffolds new MLflow pipeline steps.<br>
</li>
<li><strong><code>main.py</code></strong>: The orchestrator that references each step through Hydra configuration.<br>
</li>
<li><strong><code>MLproject</code></strong>: Defines how MLflow runs the pipeline, specifying entry points and environment details.</li>
</ul>
</section>
<section id="pipeline-components" class="level2">
<h2 class="anchored" data-anchor-id="pipeline-components">Pipeline Components</h2>
<section id="data-ingestion-get_data" class="level3">
<h3 class="anchored" data-anchor-id="data-ingestion-get_data">1. Data Ingestion (<code>get_data</code>)</h3>
<p>This module handles the retrieval of raw data, ensuring it’s stored in a structured format suitable for downstream processing. It interfaces with data sources, downloads datasets, and logs them as artifacts for version control.</p>
</section>
<section id="data-cleaning-basic_cleaning" class="level3">
<h3 class="anchored" data-anchor-id="data-cleaning-basic_cleaning">2. Data Cleaning (<code>basic_cleaning</code>)</h3>
<p>Data cleaning involves:</p>
<ul>
<li>Removing duplicates and irrelevant entries.</li>
<li>Handling missing values through imputation or removal.</li>
<li>Correcting data types and formatting issues.</li>
<li>Addressing outliers to prevent skewed model training.</li>
</ul>
</section>
<section id="exploratory-data-analysis-eda" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis-eda">3. Exploratory Data Analysis (<code>eda</code>)</h3>
<p>EDA provides insights into the dataset through:</p>
<ul>
<li>Statistical summaries of features.</li>
<li>Visualizations to identify patterns and correlations.</li>
<li>Detection of anomalies or unexpected distributions.</li>
</ul>
</section>
<section id="data-validation-data_check" class="level3">
<h3 class="anchored" data-anchor-id="data-validation-data_check">4. Data Validation (<code>data_check</code>)</h3>
<p>Before model training, data validation checks are performed to ensure:</p>
<ul>
<li>Consistency in data formats and ranges.</li>
<li>Integrity constraints are maintained.</li>
<li>Alignment with expected distributions to prevent data drift.</li>
</ul>
</section>
<section id="data-splitting-train_val_test_split" class="level3">
<h3 class="anchored" data-anchor-id="data-splitting-train_val_test_split">5. Data Splitting (<code>train_val_test_split</code>)</h3>
<p>The dataset is partitioned into:</p>
<ul>
<li><strong>Training Set</strong>: For model learning.</li>
<li><strong>Validation Set</strong>: For hyperparameter tuning and model selection.</li>
<li><strong>Test Set</strong>: For final evaluation of model performance.</li>
</ul>
</section>
<section id="model-training-train_random_forest" class="level3">
<h3 class="anchored" data-anchor-id="model-training-train_random_forest">6. Model Training (<code>train_random_forest</code>)</h3>
<p>Utilizing the Random Forest algorithm, this step involves:</p>
<ul>
<li>Training the model on the prepared dataset.</li>
<li>Logging training parameters and metrics.</li>
<li>Saving the trained model artifact for evaluation and deployment.</li>
</ul>
</section>
<section id="model-evaluation-test_regression_model" class="level3">
<h3 class="anchored" data-anchor-id="model-evaluation-test_regression_model">8. Model Evaluation (<code>test_regression_model</code>)</h3>
<p>The trained model undergoes rigorous evaluation to assess:</p>
<ul>
<li>Predictive accuracy on unseen data.</li>
<li>Generalization capabilities.</li>
<li>Potential overfitting or underfitting issues.</li>
</ul>
<hr>
</section>
</section>
<section id="setting-up-the-environment" class="level2">
<h2 class="anchored" data-anchor-id="setting-up-the-environment">Setting Up the Environment</h2>
<p>We rely on two environment files:</p>
<ol type="1">
<li><strong><code>environment.yml</code></strong>: Sets up the main environment (<code>nyc_airbnb_dev</code>) with Python 3.10, Hydra, Jupyter, and crucial Python packages (MLflow, W&amp;B, ydata-profiling, etc.).<br>
</li>
<li><strong><code>conda.yml</code></strong> (in various subfolders): Each step can be run in a mini environment with the dependencies it needs.</li>
</ol>
<p><strong>To install</strong>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> env create <span class="at">-f</span> environment.yml</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate nyc_airbnb_dev</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">wandb</span> login <span class="pp">[</span><span class="ss">your_API_key</span><span class="pp">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>After this, you can run:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>MLflow will pick up the <code>MLproject</code> file in the root directory and execute <code>main.py</code>.</p>
<hr>
</section>
<section id="pipeline-steps" class="level2">
<h2 class="anchored" data-anchor-id="pipeline-steps">Pipeline Steps</h2>
<section id="step-1-downloading-the-data" class="level3">
<h3 class="anchored" data-anchor-id="step-1-downloading-the-data">Step 1: Downloading the Data</h3>
<p>The code for <strong>downloading data</strong> is stored in <code>components/get_data</code>. We keep a couple of sample CSVs in <code>data/</code> that stand in for a real-world dataset. This step simply logs an artifact to W&amp;B.</p>
<p><strong>Code Snippet</strong> from <code>components/get_data/run.py</code></p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> go(args):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    run <span class="op">=</span> wandb.init(job_type<span class="op">=</span><span class="st">"download_file"</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    run.config.update(args)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    log_artifact(</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        args.artifact_name,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        args.artifact_type,</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        args.artifact_description,</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        os.path.join(<span class="st">"data"</span>, args.sample),</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        run,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To run just the download step:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . <span class="at">-P</span> steps=download</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="step-2-exploratory-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="step-2-exploratory-data-analysis">Step 2: Exploratory Data Analysis</h3>
<p>We have an <strong>EDA</strong> folder (<code>src/eda</code>). It contains a <code>EDA.ipynb</code> notebook, which uses <strong>ydata-profiling</strong> for generating a quick profile report of the dataset. The snippet below shows how we generate an HTML report and log it to W&amp;B.</p>
<p><strong>Code Snippet</strong> from <code>src/eda/EDA.ipynb</code></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ydata_profiling</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>profile <span class="op">=</span> ydata_profiling.ProfileReport(df)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>profile.to_file(<span class="st">"profile-report.html"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>artifact <span class="op">=</span> wandb.Artifact(</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    name<span class="op">=</span><span class="st">"profile-report.html"</span>, </span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">type</span><span class="op">=</span><span class="st">"analysis"</span>, </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span><span class="st">"Report from ydata-profiling"</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>artifact.add_file(<span class="st">"profile-report.html"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>run.log_artifact(artifact)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>We also create various plots (like price distribution) and attempt to remove obvious outliers (price <code>&lt;10</code> or <code>&gt;350</code>) to get a more reasonable dataset.</p>
<p><strong>Key Observations</strong>:<br>
- <strong>Some columns</strong> like <code>last_review</code> and <code>reviews_per_month</code> can have many missing values.<br>
- The distribution of <code>price</code> is highly skewed.<br>
- We remove out-of-bound lat/long values that are not within the known NYC boundaries.</p>
</section>
<section id="step-3-basic-data-cleaning" class="level3">
<h3 class="anchored" data-anchor-id="step-3-basic-data-cleaning">Step 3: Basic Data Cleaning</h3>
<p>A dedicated step in <code>src/basic_cleaning/</code> cleans the data after EDA reveals certain constraints.</p>
<p>We used <strong>Cookiecutter</strong> to generate the skeleton for this step and then filled in the logic. The <code>run.py</code> file:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . <span class="at">-P</span> steps=basic_cleaning</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>Core snippet</strong> from <code>src/basic_cleaning/run.py</code>:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df.drop_duplicates().reset_index(drop<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> df[<span class="st">'price'</span>].between(args.min_price, args.max_price)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[idx].copy()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> df[<span class="st">'longitude'</span>].between(<span class="op">-</span><span class="fl">74.25</span>, <span class="op">-</span><span class="fl">73.50</span>) <span class="op">&amp;</span> df[<span class="st">'latitude'</span>].between(<span class="fl">40.5</span>, <span class="fl">41.2</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> df[idx].copy()</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Log the cleaned CSV as W&amp;B artifact</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>artifact <span class="op">=</span> wandb.Artifact(</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    name<span class="op">=</span>args.output_artifact,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    <span class="bu">type</span><span class="op">=</span>args.output_type,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>    description<span class="op">=</span>args.output_description,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>artifact.add_file(fp.name)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>run.log_artifact(artifact)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It:<br>
1. Drops duplicates.<br>
2. Filters out out-of-range prices.<br>
3. Ensures lat/long within valid NYC boundary.<br>
4. Logs the cleaned dataset to W&amp;B.</p>
</section>
<section id="step-4-data-tests-validation" class="level3">
<h3 class="anchored" data-anchor-id="step-4-data-tests-validation">Step 4: Data Tests &amp; Validation</h3>
<p>We follow the concept of <strong>Data Testing</strong> to guard against “data pipeline rot.” The step is in <code>src/data_check/</code>. It uses <code>pytest</code> tests to verify that the cleaned data:</p>
<ul>
<li>Has valid column names.</li>
<li>Falls within expected lat/long boundaries.</li>
<li>Contains only known neighborhoods.</li>
<li>Distributes similarly to a reference dataset (via KL divergence).</li>
<li>Respects a minimum and maximum price range.</li>
</ul>
<p>A snippet of the test suite from <code>src/data_check/test_data.py</code>:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_similar_neigh_distrib(data: pd.DataFrame, ref_data: pd.DataFrame, kl_threshold: <span class="bu">float</span>):</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    dist1 <span class="op">=</span> data[<span class="st">'neighbourhood_group'</span>].value_counts().sort_index()</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    dist2 <span class="op">=</span> ref_data[<span class="st">'neighbourhood_group'</span>].value_counts().sort_index()</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> scipy.stats.entropy(dist1, dist2, base<span class="op">=</span><span class="dv">2</span>) <span class="op">&lt;</span> kl_threshold</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>To run</strong>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . <span class="at">-P</span> steps=data_check</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Any mismatches or anomalies raise an exception that stops the pipeline, keeping you from training on “bad” data.</p>
</section>
<section id="step-5-train-validation-test-split" class="level3">
<h3 class="anchored" data-anchor-id="step-5-train-validation-test-split">Step 5: Train-Validation-Test Split</h3>
<p>We then <strong>split</strong> our dataset into training, validation, and test sets (the last set is strictly for final model testing). The relevant code is in <code>components/train_val_test_split/</code>.</p>
<p><strong>Code Snippet</strong> from <code>components/train_val_test_split/run.py</code></p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>trainval, test <span class="op">=</span> train_test_split(</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    df,</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span>args.test_size,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span>args.random_seed,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    stratify<span class="op">=</span>df[args.stratify_by] <span class="cf">if</span> args.stratify_by <span class="op">!=</span> <span class="st">'none'</span> <span class="cf">else</span> <span class="va">None</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Both the <strong>training/validation</strong> split (“trainval_data.csv”) and the <strong>test</strong> split (“test_data.csv”) are then logged to W&amp;B.</p>
</section>
<section id="step-6-model-training-with-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="step-6-model-training-with-random-forest">Step 6: Model Training with Random Forest</h3>
<p>With a clean train-validation dataset, we build a random forest pipeline in <code>src/train_random_forest/run.py</code>. This step is heavily reliant on Hydra for configuration. We define parameters like <code>max_depth</code>, <code>n_estimators</code>, etc., in <code>config.yaml</code>.</p>
<p>Here’s a highlight from <code>run.py</code>:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_inference_pipeline(rf_config, max_tfidf_features):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    ordinal_categorical <span class="op">=</span> [<span class="st">"room_type"</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    non_ordinal_categorical <span class="op">=</span> [<span class="st">"neighbourhood_group"</span>]</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    ordinal_categorical_preproc <span class="op">=</span> OrdinalEncoder()</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    non_ordinal_categorical_preproc <span class="op">=</span> Pipeline([</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"impute"</span>, SimpleImputer(strategy<span class="op">=</span><span class="st">"most_frequent"</span>)),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"encode"</span>, OneHotEncoder())</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    ...</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    random_forest <span class="op">=</span> RandomForestRegressor(<span class="op">**</span>rf_config)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    sk_pipe <span class="op">=</span> Pipeline([</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"preprocessor"</span>, preprocessor),</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"random_forest"</span>, random_forest),</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sk_pipe, processed_features</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>In this pipeline, we handle:<br>
- <strong>Categorical</strong> columns (<code>OrdinalEncoder</code> or <code>OneHotEncoder</code>).<br>
- <strong>Numerical</strong> columns (imputation for missing values).<br>
- <strong>NLP</strong> on the <code>name</code> field using a TF-IDF vectorizer.</p>
<p>We train and evaluate on a <em>validation set</em>, logging all metrics (MAE, R^2) to W&amp;B. Finally, the pipeline (preprocessing + model) is saved to MLflow format and uploaded to W&amp;B as an artifact:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>mlflow.sklearn.save_model(</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    sk_pipe,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    export_path,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    serialization_format<span class="op">=</span>mlflow.sklearn.SERIALIZATION_FORMAT_CLOUDPICKLE,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    signature<span class="op">=</span>sig,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    input_example<span class="op">=</span>X_val[processed_features].iloc[:<span class="dv">2</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>By storing the entire pipeline, we can apply transformations consistently at inference time.</p>
<p>To run the model training step:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . <span class="at">-P</span> steps=train_random_forest</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="step-7-model-testing-promotion" class="level3">
<h3 class="anchored" data-anchor-id="step-7-model-testing-promotion">Step 7: Model Testing &amp; Promotion</h3>
<p>Lastly, we evaluate our finalized model against the <strong>test set</strong>. The code is in <code>components/test_regression_model/run.py</code>. It:</p>
<ol type="1">
<li>Downloads the <code>prod</code> model artifact from W&amp;B.<br>
</li>
<li>Loads the test dataset.<br>
</li>
<li>Generates predictions and calculates R^2 and MAE.<br>
</li>
<li>Logs test performance to W&amp;B.</li>
</ol>
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> go(args):</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    sk_pipe <span class="op">=</span> mlflow.sklearn.load_model(model_local_path)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> sk_pipe.predict(X_test)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>    r_squared <span class="op">=</span> sk_pipe.score(X_test, y_test)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    run.summary[<span class="st">'r2'</span>] <span class="op">=</span> r_squared</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    run.summary[<span class="st">'mae'</span>] <span class="op">=</span> mae</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You only run this step <strong>after</strong> a model has been tagged for production, ensuring it has proven to be stable in dev/validation.</p>
<hr>
</section>
</section>
<section id="putting-it-all-together-main.py" class="level2">
<h2 class="anchored" data-anchor-id="putting-it-all-together-main.py">Putting It All Together: <code>main.py</code></h2>
<p>The <strong><code>main.py</code></strong> script orchestrates the entire flow. It reads <strong><code>config.yaml</code></strong> via Hydra and decides which steps to run based on a comma-separated list. A minimal snippet:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>_steps <span class="op">=</span> [</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">"download"</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"basic_cleaning"</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data_check"</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data_split"</span>,</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"train_random_forest"</span>,</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># "test_regression_model" is triggered separately</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="at">@hydra.main</span>(config_name<span class="op">=</span><span class="st">'config'</span>)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> go(config: DictConfig):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>    steps_par <span class="op">=</span> config[<span class="st">'main'</span>][<span class="st">'steps'</span>]</span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>    active_steps <span class="op">=</span> steps_par.split(<span class="st">","</span>) <span class="cf">if</span> steps_par <span class="op">!=</span> <span class="st">"all"</span> <span class="cf">else</span> _steps</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"download"</span> <span class="kw">in</span> active_steps:</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>        mlflow.run(</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>            <span class="ss">f"</span><span class="sc">{</span>config[<span class="st">'main'</span>][<span class="st">'components_repository'</span>]<span class="sc">}</span><span class="ss">/get_data"</span>,</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">"basic_cleaning"</span> <span class="kw">in</span> active_steps:</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>        mlflow.run(</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>            os.path.join(hydra.utils.get_original_cwd(), <span class="st">"src"</span>, <span class="st">"basic_cleaning"</span>),</span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>            ...</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>    ...</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To execute the entire pipeline:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Or pick and choose steps:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run . <span class="at">-P</span> steps=download,basic_cleaning,data_check</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<hr>
</section>
<section id="using-cookiecutter-for-quick-pipeline-steps" class="level2">
<h2 class="anchored" data-anchor-id="using-cookiecutter-for-quick-pipeline-steps">Using Cookiecutter for Quick Pipeline Steps</h2>
<p>One of the repository’s highlights is the <strong><code>cookie-mlflow-step</code></strong> folder, which speeds up adding new steps to the pipeline:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="ex">cookiecutter</span> cookie-mlflow-step <span class="at">-o</span> src</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>It scaffolds a new directory structure containing an <code>MLproject</code>, <code>conda.yml</code>, and a <code>run.py</code> pre-populated with arguments. This is helpful for consistent, standardized pipeline steps where each step is an MLflow project.</p>
<hr>
</section>
<section id="deployment-and-workflow" class="level2">
<h2 class="anchored" data-anchor-id="deployment-and-workflow">Deployment and Workflow</h2>
<ul>
<li><p><strong>CI/CD</strong>: The <code>.github/workflows/manual.yml</code> shows how a manual GH Action can create Jira tickets for new Pull Requests.<br>
</p></li>
<li><p><strong>Release</strong>: Tagging your repo with a version number (e.g., <code>1.0.0</code>) allows you to run the pipeline from a specific commit. For instance:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="ex">mlflow</span> run https://github.com/yurimarca/build-ml-pipeline-for-short-term-rental-prices.git <span class="dt">\</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">-v</span> 1.0.0 <span class="dt">\</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">-P</span> hydra_options=<span class="st">"etl.sample='sample2.csv'"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></li>
<li><p><strong>Artifact Logging</strong>: W&amp;B captures every CSV and model artifact, so future steps or collaborators can trace lineage and retrieve them easily.</p></li>
</ul>
<hr>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>This repository combines <strong>Hydra</strong> for flexible configuration, <strong>MLflow</strong> for pipeline orchestration, and <strong>Weights &amp; Biases</strong> for experiment tracking to create a fully reproducible short-term rental price prediction pipeline in NYC.</p>
<p><strong>Key Takeaways</strong>:</p>
<ul>
<li><strong>Data integrity</strong>: By integrating data validation tests, the pipeline can fail early if data is incorrect.<br>
</li>
<li><strong>Reproducible training</strong>: Using Hydra, MLflow, and environment files ensures consistent environments and parameter definitions.<br>
</li>
<li><strong>Full pipeline tracking</strong>: From EDA to final test, each artifact is logged to W&amp;B, making it easy to revert or compare different runs.<br>
</li>
<li><strong>Extensibility</strong>: The cookiecutter approach helps you quickly add new pipeline steps or replicate the same pipeline structure in other projects.</li>
</ul>
<p>Feel free to explore the code base, and don’t hesitate to experiment by customizing steps or hyperparameters. By following this pipeline, you can keep your machine learning workflow tidy, versioned, and production-ready.</p>
<p>For a detailed walkthrough and access to the codebase, visit the <a href="https://github.com/yurimarca/build-ml-pipeline-for-short-term-rental-prices">GitHub repository</a>.</p>
<p><em>Note: This project was developed as part of the Udacity MLOps Nanodegree program.</em></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/yurimarca\.github\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>